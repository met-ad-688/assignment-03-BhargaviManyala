{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 03\n",
        "author:\n",
        "  - name: Bhargavi Manyala\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: today\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "  pdf: \n",
        "    fig-format: png\n",
        "    embed-resources: true\n",
        "    toc-depth: 2\n",
        "    geometry: \n",
        "      - landscape\n",
        "      - margin=0.5in\n",
        "    \n",
        "date-modified: today\n",
        "date-format: long\n",
        "jupyter: assignment03-venv\n",
        "execute:\n",
        "  echo: true\n",
        "  eval: true\n",
        "  output: true\n",
        "  freeze: auto\n",
        "---\n",
        "\n",
        "\n",
        "# Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from pyspark.sql import SparkSession\n",
        "import re\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "\n",
        "np.random.seed(42)\n",
        "pio.renderers.default = \"notebook+png\"\n",
        " \n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .option(\"multiLine\", \"true\")\n",
        "    .option(\"escape\", \"\\\"\")  \n",
        "    .csv(\"lightcast_job_postings.csv\")\n",
        ")\n",
        "\n",
        "#df.show(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Relational Tables \n",
        "\n",
        "## Loactions Table\n",
        "`LOCATION_ID (Primary Key)`,`LOCATION`, `CITY_NAME`, `STATE_NAME`, `COUNTY_NAME`,`MSA`, `MSA_NAME`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "\n",
        "locations_df = (\n",
        "    df.select(\n",
        "        \"LOCATION\",\n",
        "        \"CITY_NAME\",\n",
        "        \"STATE_NAME\",\n",
        "        \"COUNTY_NAME\",\n",
        "        \"MSA\",\n",
        "        \"MSA_NAME\"\n",
        "    )\n",
        "    .distinct()\n",
        "    .withColumn(\"LOCATION_ID\", monotonically_increasing_id())\n",
        "    .select(\n",
        "        \"LOCATION_ID\",\n",
        "        \"LOCATION\",\n",
        "        \"CITY_NAME\",\n",
        "        \"STATE_NAME\",\n",
        "        \"COUNTY_NAME\",\n",
        "        \"MSA\",\n",
        "        \"MSA_NAME\"\n",
        "    )\n",
        "    .orderBy(\"LOCATION_ID\")\n",
        ")\n",
        "\n",
        "locations_df.createOrReplaceTempView(\"locations\")\n",
        "\n",
        "locations = locations_df.toPandas()\n",
        "locations.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Companies Table\n",
        "`COMPANY_ID (Primary Key)`, `COMPANY`, `COMPANY_NAME`, `COMPANY_RAW`, `COMPANY_IS_STAFFING`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "companies_df = (\n",
        "    df.select(\n",
        "        \"COMPANY\",\n",
        "        \"COMPANY_NAME\",\n",
        "        \"COMPANY_RAW\",\n",
        "        \"COMPANY_IS_STAFFING\"\n",
        "    )\n",
        "    .distinct()\n",
        "    .withColumn(\"COMPANY_ID\", monotonically_increasing_id())\n",
        "    .select(\n",
        "        \"COMPANY_ID\",\n",
        "        \"COMPANY\",\n",
        "        \"COMPANY_NAME\",\n",
        "        \"COMPANY_RAW\",\n",
        "        \"COMPANY_IS_STAFFING\"\n",
        "    )\n",
        "    .orderBy(\"COMPANY_ID\")\n",
        ")\n",
        "\n",
        "companies_df.createOrReplaceTempView(\"companies\")\n",
        "\n",
        "companies = companies_df.toPandas()\n",
        "companies.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Industries Table\n",
        "\n",
        "`INDUSTRY_ID (Primary Key)`, `NAICS_2022_6`, `NAICS_2022_6_NAME`, `SOC_5`, `SOC_5_NAME`,`LOT_SPECIALIZED_OCCUPATION_NAME`,`LOT_OCCUPATION_GROUP`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "industries_df = (\n",
        "    df.select(\n",
        "        \"NAICS_2022_6\",\n",
        "        \"NAICS_2022_6_NAME\",\n",
        "        \"SOC_5\",\n",
        "        \"SOC_5_NAME\",\n",
        "        \"LOT_SPECIALIZED_OCCUPATION_NAME\",\n",
        "        \"LOT_OCCUPATION_GROUP\"\n",
        "    )\n",
        "    .distinct()\n",
        "    .withColumn(\"INDUSTRY_ID\", monotonically_increasing_id())\n",
        "    .select(\n",
        "        \"INDUSTRY_ID\",\n",
        "        \"NAICS_2022_6\",\n",
        "        \"NAICS_2022_6_NAME\",\n",
        "        \"SOC_5\",\n",
        "        \"SOC_5_NAME\",\n",
        "        \"LOT_SPECIALIZED_OCCUPATION_NAME\",\n",
        "        \"LOT_OCCUPATION_GROUP\"\n",
        "    )\n",
        "    .orderBy(\"INDUSTRY_ID\")\n",
        ")\n",
        "\n",
        "industries_df.createOrReplaceTempView(\"industries\")\n",
        "\n",
        "industries = industries_df.toPandas()\n",
        "industries.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Job Postings Table\n",
        "\n",
        "`ID (Primary Key)`, `TITLE_CLEAN`, `COMPANY_ID (FK to companies)`, `INDUSTRY_ID (FKto industries)`, `EMPLOYMENT_TYPE_NAME`, `REMOTE_TYPE_NAME`, `BODY`,`MIN_YEARS_EXPERIENCE`, `MAX_YEARS_EXPERIENCE`, `SALARY`, `SALARY_FROM`,`SALARY_TO`, `LOCATION_ID (FK to locations)`, `POSTED`, `EXPIRED`, `DURATION`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "job_postings_df = df.select(\n",
        "    \"ID\",\n",
        "    \"TITLE_CLEAN\",\n",
        "    \"BODY\",\n",
        "    \"COMPANY\",            \n",
        "    \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    \"MIN_YEARS_EXPERIENCE\",\n",
        "    \"MAX_YEARS_EXPERIENCE\",\n",
        "    \"SALARY\",\n",
        "    \"SALARY_FROM\",\n",
        "    \"SALARY_TO\",\n",
        "    \"LOCATION\",           \n",
        "    \"NAICS_2022_6\",       \n",
        "    \"POSTED\",\n",
        "    \"EXPIRED\",\n",
        "    \"DURATION\"\n",
        ").withColumnRenamed(\"ID\", \"JOB_ID\").orderBy(\"JOB_ID\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Foreign Keys to Job Postings Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "job_postings_df = job_postings_df.join(\n",
        "    companies_df.select(\"COMPANY\", \"COMPANY_ID\"),\n",
        "    on=\"COMPANY\", \n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Join with Locations Table to get LOCATION_ID\n",
        "job_postings_df = job_postings_df.join(\n",
        "    locations_df.select(\"LOCATION\", \"LOCATION_ID\"),\n",
        "    job_postings_df.LOCATION == locations_df.LOCATION,\n",
        "    how=\"left\"\n",
        ").drop(\"LOCATION\")\n",
        "\n",
        "# Join with Industries Table to get INDUSTRY_ID\n",
        "job_postings_df = job_postings_df.join(\n",
        "    industries_df.select(\"NAICS_2022_6\", \"INDUSTRY_ID\"),\n",
        "    job_postings_df.NAICS_2022_6 == industries_df.NAICS_2022_6,\n",
        "    how=\"left\"\n",
        ").drop(\"NAICS_2022_6\")\n",
        "\n",
        "job_postings_df = job_postings_df.drop(\"COMPANY\", \"LAT-LONG\")\n",
        "job_postings_df.createOrReplaceTempView(\"job_postings\")\n",
        "\n",
        "job_postings_df.show(truncate=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Casting salary and experience columns\n",
        "\n",
        "## Computing medians and Imputing missing salaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
        "       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\")) \\\n",
        "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\n",
        "\n",
        "# Computing medians for salary columns\n",
        "def compute_median(sdf, col_name):\n",
        "    return sdf.approxQuantile(col_name, [0.5], 0.01)[0]\n",
        "\n",
        "median_from = compute_median(df, \"SALARY_FROM\")\n",
        "median_to   = compute_median(df, \"SALARY_TO\")\n",
        "median_salary = compute_median(df, \"SALARY\")\n",
        "\n",
        "print(\"Medians:\", median_from, median_to, median_salary)\n",
        "\n",
        "# Imputing missing salaries, but not experience\n",
        "df = df.fillna({\n",
        "    \"SALARY_FROM\": median_from,\n",
        "    \"SALARY_TO\": median_to,\n",
        "    \"SALARY\": median_salary\n",
        "})\n",
        "\n",
        "# Computing average salary\n",
        "df = df.withColumn(\n",
        "    \"Average_Salary\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2\n",
        ")\n",
        "\n",
        "# Selecting required columns\n",
        "export_cols = [\n",
        "    \"Average_Salary\",\n",
        "    \"SALARY\",\n",
        "    \"EDUCATION_LEVELS_NAME\",\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    \"MAX_YEARS_EXPERIENCE\",\n",
        "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"\n",
        "]\n",
        "\n",
        "df_selected = df.select(*export_cols)\n",
        "\n",
        "pdf_selected = df_selected.toPandas()\n",
        "pdf_selected.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning Education column and  Exporting Cleaned Data\n",
        "\n",
        "*I referred to Claude Sonnet 4 for prompts and sample code ideas, but I wrote and adapted the final implementation myself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# To remove \\n and \\r\n",
        "pdf_selected[\"EDUCATION_LEVELS_NAME\"] = (\n",
        "    pdf_selected[\"EDUCATION_LEVELS_NAME\"]\n",
        "    .astype(str)               \n",
        "    .str.replace(r\"[\\n\\r]\", \"\", regex=True)\n",
        "    .str.strip()                \n",
        ")\n",
        "pdf_selected.to_csv(\"data/lightcast_cleaned.csv\", index=False)\n",
        "pdf_selected.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exporting Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Data cleaning complete. Rows retained:\", len(pdf_selected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Query 1: Salary Distribution by Industry and Employment Type\n",
        "\n",
        "## Salary Distribution by Employment Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "import plotly.io as pio\n",
        "\n",
        "df_query1 = df.select(\n",
        "    \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"NAICS2_NAME\",\n",
        "    \"SALARY\"\n",
        ")\n",
        "\n",
        "pdf_query1 = df_query1.toPandas()\n",
        "\n",
        "pdf_query1 = pdf_query1[pdf_query1[\"SALARY\"] > 0]\n",
        "\n",
        "pdf_query1[\"EMPLOYMENT_TYPE_NAME\"] = (\n",
        "    pdf_query1[\"EMPLOYMENT_TYPE_NAME\"]\n",
        "    .astype(str) \n",
        "    .apply(lambda x: re.sub(r\"[^\\x00-\\x7F]+\", \"\", x)) \n",
        "    .str.strip()  \n",
        ")\n",
        "pdf_query1 = pdf_query1[pdf_query1[\"EMPLOYMENT_TYPE_NAME\"] != \"None\"]\n",
        "\n",
        "median_salaries = pdf_query1.groupby(\"EMPLOYMENT_TYPE_NAME\")[\"SALARY\"].median()\n",
        "\n",
        "sorted_employment_types = median_salaries.sort_values(ascending=False).index\n",
        "\n",
        "pdf_query1[\"EMPLOYMENT_TYPE_NAME\"] = pd.Categorical(\n",
        "    pdf_query1[\"EMPLOYMENT_TYPE_NAME\"],\n",
        "    categories=sorted_employment_types,\n",
        "    ordered=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig = px.box(\n",
        "    pdf_query1,\n",
        "    x=\"EMPLOYMENT_TYPE_NAME\",\n",
        "    y=\"SALARY\",\n",
        "    title=\"Salary Distribution by Employment Type\",\n",
        "    color_discrete_sequence=[\"#CC0000\"],  \n",
        "    boxmode=\"group\",\n",
        "    points=\"outliers\" \n",
        ")\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(\n",
        "        text=\"Salary Distribution by Employment Type\",\n",
        "        font=dict(size=20, family=\"Arial Black\", color=\"black\"),  \n",
        "        x=0.5  \n",
        "    ),\n",
        "    xaxis=dict(\n",
        "        title=dict(\n",
        "            text=\"Employment Type\",\n",
        "            font=dict(size=14, family=\"Arial Black\", color=\"black\")  \n",
        "        ),\n",
        "        tickangle=-45,\n",
        "        tickfont=dict(size=12, family=\"Arial Black\", color=\"black\"),  \n",
        "        showline=True,\n",
        "        linecolor=\"black\",\n",
        "        linewidth=2,\n",
        "        mirror=True,\n",
        "        showgrid=False,  \n",
        "        categoryorder=\"array\",\n",
        "        categoryarray=sorted_employment_types.tolist() \n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title=dict(\n",
        "            text=\"Salary (1000 $)\",\n",
        "            font=dict(size=14, family=\"Arial Black\", color=\"black\")  \n",
        "        ),\n",
        "        tickvals=[0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000],\n",
        "        ticktext=[\"0\", \"50k\", \"100k\", \"150k\", \"200k\", \"250k\", \"300k\", \"350k\", \"400k\", \"450k\", \"500k\"],\n",
        "        tickfont=dict(size=12, family=\"Arial Black\", color=\"black\"), \n",
        "        showline=True,\n",
        "        linecolor=\"black\",\n",
        "        linewidth=2,\n",
        "        mirror=True,\n",
        "        showgrid=True,          \n",
        "        gridcolor=\"lightgray\", \n",
        "        gridwidth=0.5             \n",
        "    ),\n",
        "    font=dict(family=\"Arial\", size=16, color=\"black\"),\n",
        "    boxgap=0.7,\n",
        "    plot_bgcolor=\"white\",\n",
        "    paper_bgcolor=\"white\",\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    width=850,\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "fig.write_html(\"output/Q1.html\")\n",
        "fig.write_image(\"output/Q1.png\", width = 850, height = 500, scale=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./output/Q1.png){ width=90% }"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "assignment03-venv",
      "language": "python",
      "display_name": "Python (assignment03-venv)",
      "path": "/home/ubuntu/.local/share/jupyter/kernels/assignment03-venv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}